<HTML><HEAD><TITLE></TITLE><link rel="stylesheet" type="text/css" href="defaultpage2.css"></HEAD>

<body TEXT="#ffffff" BGCOLOR="#666666" LINK="#ff9933" VLINK="#ff9933" ALINK="#ff9933">

<font size="-2"><BR><table width=1000 cellpadding=0 cellspacing=0 align=center><tr>

<td valign=top><font color="ffffff"><B>Publications</B> 
(<A HREF="FullPublication.html">Full Publication List</A>; 
<!-----<A HREF="http://www.informatik.uni-trier.de/~ley/db/indices/a-tree/w/Wang:Charlie_C=_L=.html" target="new">Entry@DBLP</A>; --------->
<A HREF="http://www.researcherid.com/rid/B-3730-2010" target="new">ResearcherID</A>; 
<A HREF="http://scholar.google.com/citations?user=-EXti64AAAAJ&hl=en" target="new">Google Scholar</A>)<B>:</B> 
<a href="publication2005.html">2001-2005</a>; <a href="publication2010.html">2006-2010</a>; <a href="publication2015.html">2011-2015</a>; 
<a href="#2016">2016</a>; <a href="#2017">2017</a>; <a href="#2018">2018</a>; <a href="#2019">2019</a>; <a href="#UnderReview">Under Review</a>

<BR><BR>
<B>Disclaimer:</B> The documents listed on this page are copyright-protected. By clicking on the [PDF] links below, you confirm that you or your institution have the right to access the corresponding pdf file.

<BR><BR><B>Recent Papers</B>
<BR><BR>







<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/CAD3DHumanSparseRep.jpg" width="160" border="0"></td><td width=830 valign=top>
Yiu-Bun Wu, Bin Liu, Xiuping Liu, and <B>Charlie C.L. Wang</B>, "Data-driven human modeling by sparse representation", 
Computer-Aided Design, accepted. <a href="pubs/CAD3DHumanSparseRep.pdf" target="new">[PDF]</a>
<BR><BR>
<B>Abstract</B>
<BR>
Data-driven methods for modeling the realistic shape of 3D human bodies need to access datasets that contain a large amount of 3D human models. A very challenging problem is to find an appropriate representation for storing these 3D models as their raw data representations in triangular meshes take a large amount of space. We develop a method based on sparse representation in this paper to represent 3D human models as signals of patches. Unlike the general mesh compression approaches, all mesh models used in a data-driven human modeling framework have the same mesh connectivity. By using this property, we segment a human model into patches containing the same number of vertices. L0-learning algorithm is selected to train an overcomplete dictionary matrix, which in turn introduced sparse representation of the dataset. Patch signals of individual human models can then be extracted by using the dictionary matrix. With the ease of balance control between sparsity and accuracy that is featured by the chosen learning algorithm, a representation with high compression ratio and low shape-approximation error can be determined. The results have been compared with the widely used statistic representation based on <I>principal component analysis</I> (PCA) to verify the effectiveness of our approach. Moreover, the method for using sparse representation in the regression-based statistical modeling of 3D human models has been presented at the end of the paper.
<p></p></tr>
</table>
<BR><BR>




<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/CADContourParaToolpath.jpg" width="160" border="0"></td><td width=830 valign=top>
Tim Kuipers, Eugeni L. Doubrovski, Jun Wu, and <B>Charlie C.L. Wang</B>, "<a href="https://doi.org/10.1016/j.cad.2020.102907" target="new">A framework for adaptive width control of dense contour-parallel toolpaths in fused deposition modeling</a>", Computer-Aided Design, accepted. 


<a href="https://arxiv.org/abs/2004.13497" target="new">[arXiv]</a> 
<BR><BR>
<B>Abstract</B>
<BR>
3D printing techniques such as Fused Deposition Modeling (FDM) have enabled the fabrication of complex geometry quickly and cheaply. High stiffness parts are produced by filling the 2D polygons of consecutive layers with contour-parallel extrusion toolpaths. Uniform width toolpaths consisting of inward offsets from the outline polygons produce over- and underfill regions in the center of the shape, which are especially detrimental to the mechanical performance of thin parts. In order to fill shapes with arbitrary diameter densely the toolpaths require adaptive width. Existing approaches for generating toolpaths with adaptive width result in a large variation in widths, which for some hardware systems is difficult to realize accurately. In this paper we present a framework which supports multiple schemes to generate toolpaths with adaptive width, by employing a function to decide the number of beads and their widths. Furthermore, we propose a novel scheme which reduces extreme bead widths, while limiting the number of altered toolpaths. We statistically validate the effectiveness of our framework and this novel scheme on a data set of representative 3D models, and physically validate it by developing a technique, called back pressure compensation, for off-the-shelf FDM systems to effectively realize adaptive width.
<p></p></tr>
</table>
<BR><BR>




<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/CASELearningDecomp3DP.jpg" width="160" border="0"></td><td width=830 valign=top>
Chenming Wu, Yong-Jin Liu, and <B>Charlie C.L. Wang</B>, "<a href="http://arxiv.org/abs/2004.03450" target="new">Learning to accelerate decomposition for multi-directional 3D printing</a>", 2020 IEEE International Conference on Automation Science and Engineering (CASE 2020), Hong Kong, August 20-24, 2020. 
<a href="https://github.com/chenming-wu/pymdp/" target="new">[Source Code]</a>
<a href="https://youtu.be/OOkxNKGhN7A" target="new">[Video@YouTube]</a> 
<BR><BR>
<B>Abstract</B>
<BR>
Multi-directional 3D printing has the capability of decreasing or eliminating the need for support structures. 
Recent work proposed a beam-guided search algorithm to find an optimized sequence of plane-clipping, which gives volume decomposition of a given 3D model. 
Different printing directions are employed in different regions to fabricate a model with tremendously less support (or even no support in many cases). 
To obtain optimized decomposition, a large beam width needs to be used in the search algorithm, leading to a very time-consuming computation. 
In this paper, we propose a learning framework that can accelerate the beam-guided search by using a smaller number of the original beam width to obtain results with similar quality. 
Specifically, we use the results of beam-guided search with large beam width to train a scoring function for candidate clipping planes based on six newly proposed feature metrics. 
With the help of these feature metrics, both the current and the sequence-dependent information are captured by the neural network to score candidates of clipping. 
As a result, we can achieve around 3x computational speed. We test and demonstrate our accelerated decomposition on a large dataset of models for 3D printing.
<p></p></tr>
</table>
<BR><BR>


<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/TROSoftKinematics.jpg" width="160" border="0">
</td>
<td width=830 valign=top>
Guoxin Fang, Christopher-Denny Matte, Rob B.N. Scharff, Tsz-Ho Kwok, and <B>Charlie C.L. Wang</B>, "<a href="https://doi.org/10.1109/TRO.2020.2985583" target="new">Kinematics of soft robots by geometric computing</a>", IEEE Transactions on Robotics, accepted. 
<a href="pubs/TROSoftKinematics.pdf" target="new">[PDF]</a> 
<a href="https://youtu.be/RTc0wWSmDFw" target="new">[Video@YouTube]</a> 
<BR><BR>

(This is an extended version of the paper - <a href="https://doi.org/10.1109/ICRA.2018.8461088" target="new">Geometry-based direct simulation for multi-material soft robots</a>, 
which is published in 2018 IEEE ICRA Conference, Brisbane, Australia, May 21-25, 2018.) 
<!--------- <a href="https://youtu.be/vTKMGV1uf_c" target="new">[Video@YouTube]</a>)  ----->
<BR><BR>
<B>Abstract</B><BR>
Robots fabricated with soft materials can provide higher flexibility and thus better safety while interacting in unpredictable situations. However, the usage of soft material makes it challenging to predict the deformation of a continuum body under actuation and therefore brings difficulty to the kinematic control of its movement. In this paper, we present a geometry-based framework for computing the deformation of soft robots within the range of linear material elasticity. After formulating both manipulators and actuators with geometry elements, deformation can be efficiently computed by solving a constrained optimization problem. Based on its efficiency, forward and inverse kinematics for soft manipulators can be effectively solved by an iterative algorithm. Meanwhile, components with multiple materials can also be geometrically modeled in our framework with the help of a simple calibration. Numerical and physical experimental tests are conducted on soft manipulators driven by different actuators with large deformation to demonstrate the performance of our approach.
<BR>
<p></p></tr>
</table>
<BR><BR>


<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/TASEDepthImageCNNCompletion.jpg" width="161" border="0"></td><td width=830 valign=top>
Chuhua Xian, Dongjiu Zhang, Chengkai Dai, and <B>Charlie C.L. Wang</B>, "<a href="https://doi.org/10.1109/TASE.2020.3002069" target="new">Fast generation of high fidelity RGB-D images by deep-learning with adaptive convolution</a>", IEEE Transactions on Automation Science and Engineering, accepted. 
<a href="https://arxiv.org/abs/2002.05067" target="new">[arXiv]</a> 
<a href="https://github.com/chuhuaxian/HF-RGBD" target="new">[Source Code]</a> 
<a href="https://www.mae.cuhk.edu.hk/~cwang/Projects/RGBDCompletionCNNDataset.zip" target="new">[Dataset]</a> 
<BR><BR>
<B>Abstract</B>
<BR>
Using the raw data from consumer-level RGB-D cameras as input, we propose a deep-learning based approach to efficiently generate RGB-D images with completed information in high resolution. To process the input images in low resolution with missing regions, new operators for adaptive convolution are introduced in our deep-learning network that consists of three cascaded modules - the completion module, the refinement module and the super-resolution module. The completion module is based on an architecture of encoder-decoder, where the features of input raw RGB-D will be automatically extracted by the encoding layers of a deep neural-network. The decoding layers are applied to reconstruct the completed depth map, which is followed by a refinement module to sharpen the boundary of different regions. For the super-resolution module, we generate RGB-D images in high resolution by multiple layers for feature extraction and a layer for up-sampling. Benefited from the adaptive convolution operators newly proposed in this paper, our results outperform the existing deep-learning based approaches for RGB-D image complete and super-resolution. As an end-to-end approach, high fidelity RGB-D images can be generated efficiently at the rate of around 21 frames per second.
<p></p></tr>
</table>
<BR><BR>

<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/TASETrajectoryPlanning.jpg" width="160" border="0"></td><td width=830 valign=top>
Chengkai Dai, Sylvain Lefebvre, Kai-Ming Yu, Jo M.P. Geraedts, and <B>Charlie C.L. Wang</B>, 
"<a href="https://doi.org/10.1109/TASE.2020.2974771" target="new">Planning jerk-optimized trajectory with discrete-time constraints for redundant robots</a>", IEEE Transactions on Automation Science and Engineering, accepted. 
<a href="https://arxiv.org/abs/1909.06570" target="new">[arXiv]</a> 
<a href="https://youtu.be/e8ISmh9MPrE" target="new">[Video@YouTube]</a> <BR><BR>
<B>Abstract</B>
<BR>
We present a method for effectively planning the motion trajectory of robots in manufacturing tasks, the tool-paths of which are usually complex and have a large number of discrete-time constraints as waypoints. Kinematic redundancy also exists in these robotic systems. The jerk of motion is optimized in our trajectory planning method at the meanwhile of fabrication process to improve the quality of fabrication. Our method is based on a sampling strategy and consists of two major parts. After determining an initial path by graph-search, a greedy algorithm is adopted to optimize a path by locally applying adaptive filers in the regions with large jerks. The filtering result is obtained by numerical optimization. In order to achieve efficient computation, an adaptive sampling method is developed for learning a collision-indication function that is represented as a support-vector machine. Applications in robot-assisted 3D printing are given in this paper to demonstrate the functionality of our approach.
<p></p></tr>
</table>
<BR><BR>

<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/RoboSoft2020ForceSensingControl.jpg" width="160" border="0">
</td>
<td width=830 valign=top>
Alice Buso, Rob B.N. Scharff, Eugeni L. Doubrovski, Jun Wu, <B>Charlie C.L. Wang</B>, and Peter Vink, 
"Soft robotic module for sensing and controlling contact force", 
IEEE International Conference on Soft Robotics (RoboSoft 2020), Yale University, New Haven, Connecticut, USA, April 6-9, 2020. 
<a href="pubs/RoboSoft2020ForceSensingControl.pdf" target="new">[PDF]</a> <a href="https://youtu.be/kVt9N1XT10A" target="new">[Video@YouTube]</a> <BR><BR>
<B>Abstract</B><BR>
This work presents a soft robotic module that can sense and control contact forces. The module is composed of a foam spring encapsulated by a pneumatic bellow that can be inflated to increase its stiffness. Optical sensors and a light source are integrated inside the soft pneumatic module. Changes in shape of the module lead to a variation in light reflectivity, which is captured by the optical sensors. These shape measurements are combined with air pressure measurements to predict the contact force through a machine learning model. Using these predictions, a closed-loop control of the contact force was implemented. The modules can be applied to realize pressure distribution control in support devices such as seats and mattresses. The presented method is robust and low-cost, can measure both shape and contact force, and does not require (rigid) sensors to be present at the movable contact interface between the support device and the user.
<BR>
<p></p></tr>
</table>
<BR><BR>


<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/TASEMultiDir3DP.jpg" width="160" border="0">
</td>
<td width=830 valign=top>
Chenming Wu, Chengkai Dai, Guoxin Fang, Yong-Jin Liu, and <B>Charlie C.L. Wang</B>, "<a href="https://doi.org/10.1109/TASE.2019.2938219" target="new">General support-effective decomposition for multi-directional 3-D printing</a>", IEEE Transactions on Automation Science and Engineering, vol.17, no.2, pp.599-610, April 2020. 
<a href="https://arxiv.org/abs/1812.00606" target="new">[arXiv]</a> 
<a href="https://github.com/chenming-wu/pymdp/" target="new">[Source Code]</a> 
<a href="https://youtu.be/8SOxeFh9SDo" target="new">[Video@YouTube]</a> 
<a href="https://3dprint.com/231922/researchers-decrease-support-structures-for-models-through-multidirectional-3d-printing/" target="new">[Report@3DPrint.com]</a>
<BR><BR>
<B>Abstract</B><BR>
We present a method for fabricating general models with multi-directional 3D printing systems by printing different model regions along different directions. The core of our method is a support-effective volume decomposition algorithm that minimizes the area of the regions with large overhangs. A beam-guided searching algorithm with manufacturing constraints determines the optimal volume decomposition, which is represented by a sequence of clipping planes. While current approaches require manually assembling separate components into a final model, our algorithm allows for directly printing the final model in a single pass. It can also be applied to models with loops and handles. A supplementary algorithm generates special supporting structures for models where supporting structures for large overhangs cannot be eliminated. We verify the effectiveness of our method using two hardware systems: a Cartesian-motion based system and an angular-motion based system. A variety of 3-D models have been successfully fabricated on these systems.
<BR>
<p></p></tr>
</table>
<BR><BR>



<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/SMOSpaceTimeTopoOpt.jpg" width="160" border="0">
</td>
<td width=830 valign=top>
Weiming Wang, Dirk Munro, <B>Charlie C.L. Wang</B>, Fred van Keulen, and Jun Wu, 
"<a href="https://doi.org/10.1007/s00158-019-02420-6" target="new">Space-time topology optimization for additive manufacturing: concurrent optimization of structural layout and fabrication sequence</a>", Structural and Multidisciplinary Optimization, vol.61, pp.1-18, January 2020. <B>(ISSMO/Springer Prize)</B>  

<a href="http://homepage.tudelft.nl/z0s1z/projects/2019-space-time-topology-optimization.html" target="new">[Project]</a> 
<a href="pubs/SMOSpaceTimeTopoOpt.pdf" target="new">[PDF]</a> 
<BR><BR>
<B>Abstract</B><BR>
The design of optimal structures and the planning of (additive manufacturing) fabrication sequences have been considered typically as two separate tasks that are performed consecutively. In the light of recent advances in robot-assisted (wire-arc) additive manufacturing which enable addition of material along curved surfaces, we present a novel topology optimization formulation which concurrently optimizes the structure and the fabrication sequence. For this, two sets of design variables, i.e. a density field for defining the structural layout, and a time field which determines the fabrication process order, are simultaneously optimized. These two fields allow to generate a sequence of intermediate structures, upon which manufacturing constraints (e.g. fabrication continuity and speed) are imposed. The proposed space-time formulation is general, and is demonstrated on three fabrication settings, considering self-weight of the intermediate structures, process-dependent critical loads, and time-dependent material properties.
<BR>
<p></p></tr>
</table>
<BR><BR>


<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/MDBonding3DP.jpg" width="160" border="0">
</td>
<td width=830 valign=top>
Lars Rossing, Rob B.N. Scharff, Bryan Chompff, <B>Charlie C.L. Wang</B>, and Eugeni L. Doubrovski, "<a href="https://doi.org/10.1016/j.matdes.2019.108254" target="new">Bonding between silicones and thermoplastics using 3D printed mechanical interlocking</a>", Materials & Design, vol.186, article no.108254, January 2020.
<BR><BR>
<B>Abstract</B><BR>
Silicones have desirable properties such as skin-safety, high temperature-resistance, and flexibility. Many applications require the presence of a hard body connected to the silicone. Traditionally, it has been difficult to create strong bonding between silicones and hard materials. In this study, a technique is presented to control the bonding strength between silicones and thermoplastics through mechanical interlocking. This is realized through a hybrid fabrication method where silicone is cast onto a 3D-printed mold and structure. The influence of the structure's design parameters on the bonding strength is explored through theoretical modeling and physical testing while the manufacturability of the 3D-printed structure is ensured. A CAD tool is developed to automatically apply the bonding structure to product surfaces. The user interface visualizes the theoretical strength of the cells as the designer adjusts the cell parameters, allowing the designer to iteratively optimize the structure to the product's load case. The bonding strength of the presented mechanical interlocking structure is more than 5.5 times higher than can be achieved with a commercially available primer. The presented technique enables custom digital design and manufacturing of durable free-form parts. This is demonstrated through application of the technique in over-molded products, airtight seals, and soft pneumatic actuators.
<BR>
<p></p></tr>
</table>
<BR><BR>



<a name="2019"></a>


<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/TMECHBendingSensor.jpg" width="160" border="0">
</td>
<td width=830 valign=top>
Rob B.N. Scharff, Rens M. Doornbusch, Eugeni L. Doubrovski, Jun Wu, Jo M.P. Geraedts, and <B>Charlie C.L. Wang</B>, 
"<a href="http://doi.org/10.1109/TMECH.2019.2929818" target="new">Color-based proprioception of soft actuators interacting with objects</a>", IEEE/ASME Transactions on Mechatronics, vol.24, no.5, pp.1964-1973, October 2019. 
<a href="pubs/TMECHBendingSensor.pdf" target="new">[PDF]</a> 
<a href="https://youtu.be/zgOexw8YLQc" target="new">[Video@YouTube]</a> 
<a href="https://3dprint.com/250730/tu-delft-researchers-create-soft-robotics-that-respond-color-based-sensors/" target="new">[Report@3DPrint.com]</a> 
<BR><BR>
<B>Abstract</B><BR>
Actuators using soft materials feature a large number of degrees of freedom. This tremendous flexibility allows a soft actuator to passively adapt its shape to the objects under interaction. In this paper we propose a novel proprioception method for soft actuators during real-time interaction with priorly unknown objects. Firstly, we design a color-based sensing structure that instantly translates the inflation of a bellow into changes in color, which are subsequently detected by a miniaturized color sensor. The color sensor is small and thus multiple of them can be integrated into soft pneumatic actuators to reflect local deformations. Secondly, we make use of a <I>Feed-forward Neural Network</I> (FNN) to reconstruct a multivariate global shape deformation from local 
color signals. Our results demonstrate that deformations of the actuator during interaction, including the sigmoid-like shape, can be accurately reconstructed. The accurate shape sensing represents a significant step towards closed-loop control of soft robots in unstructured environments.
<BR>
<p></p></tr>
</table>
<BR><BR>



<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/RALDeepNBVPlanner.jpg" width="160" border="0">
</td>
<td width=830 valign=top>
Chenming Wu, Rui Zeng, Jia Pan, <B>Charlie C.L. Wang</B>, and Yong-Jin Liu, 
"<a href="https://doi.org/10.1109/LRA.2019.2924125" target="new">Plant phenotyping by deep-learning based planner for multi-robots</a>", 
IEEE Robotics and Automation Letters, Presented at IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2019), Macau, November 4-8, 2019, vol.4, no.4, pp.3113-3120, October 2019. 
<a href="pubs/RALDeepNBVPlanner.pdf" target="new">[PDF]</a> 
<a href="https://youtu.be/XusxgEczHrQ" target="new">[Video@YouTube]</a> 
<BR><BR>
<B>Abstract</B><BR>
Manual plant phenotyping is slow, error-prone and labor-intensive. In this paper, we present an automated robotic system for fast, precise and noninvasive measurements using a new deep-learning based next-best view planning pipeline.
Specifically, we first use a deep neural network to estimate a set of candidate voxels for next scanning. Next, we cast rays from these voxels to determine the optimal viewpoints. We empirically evaluate our method in simulation and real-world robotic experiments with up to three robotic arms to demonstrate its efficiency and effectiveness. One advantage of our new pipeline is that it can be easily extended to a multi-robot system where multiple robots move simultaneously according to the planned motions. Our system significantly outperforms the single-robot systems in flexibility and planning time. High-throughput phenotyping can be made practically.
<BR>
<p></p></tr>
</table><BR><BR>



<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/SPM19CrossFill.jpg" width="160" border="0">
</td>
<td width=830 valign=top>
Tim Kuipers, Jun Wu, and <B>Charlie C.L. Wang</B>, 
"<a href="https://doi.org/10.1016/j.cad.2019.05.003" target="new">CrossFill: Foam structure with graded density for continuous material extrusion</a>", 
Computer-Aided Design, Special Issue of 2019 Symposium on Solid and Physical Modeling, June 17-19, 2019, Vancouver, Canada, vol.114, pp.37-50, September 2019. <B>(Best Paper Award - 2nd Place)</B>
<a href="pubs/SPM19CrossFill.pdf" target="new">[PDF]</a> 
<a href="https://youtu.be/lcLcsprxIHw" target="new">[Video@YouTube]</a> 
<a href="https://3dprint.com/247151/density-graded-structure-for-extrusion-3d-printing-of-fgm/" target="new">[Report@3DPrint.com]</a>
<BR><BR>
<B>Abstract</B><BR>
The fabrication flexibility of 3D printing has sparked a lot of interest in designing structures with spatially graded material properties. In this paper, we propose a new type of density graded structure that is particularly designed for 3D printing systems based on filament extrusion. In order to ensure high-quality fabrication results, extrusion-based 3D printing requires not only that the structures areself-supporting, but also that extrusion toolpaths are continuous and free of self-overlap. The structure proposed in this paper, called CrossFill, complies with these requirements. In particular, CrossFill is a self-supporting foam structure, for which each layer is fabricated by a single, continuous and overlap-free path of material extrusion. Our method for generating CrossFill is based on a space-filling surface that employs spatially varying subdivision levels. Dithering of the subdivision levels is performed to accurately reproduce a prescribed density distribution. We demonstrate the effectiveness of CrossFill on a number of experimental tests and applications.
<BR>
<p></p></tr>
</table>
<BR><BR>




<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/SIG19FabForm.png" width="160" border="0">
</td>
<td width=830 valign=top>
Xiaoting Zhang, Guoxin Fang, Melina Skouras, Gwenda Gieseler, <B>Charlie C.L. Wang</B>, and Emily Whiting, 
"<a href="https://doi.org/10.1145/3306346.3322988" target="new">Computational design of fabric formwork</a>", 
ACM Transactions on Graphics (SIGGRAPH 2019), vol.38, no.4, article no.109 (13 pages), July 2019. 
<a href="pubs/SIG19FabForm.pdf" target="new">[PDF]</a> 
<a href="https://youtu.be/GotvnT9JIKk" target="new">[Video@YouTube]</a> 
<BR><BR>
<B>Abstract</B><BR>
We present an inverse design tool for fabric formwork - a process where flat panels are sewn together to form a fabric container for casting a plaster sculpture. Compared to 3D printing techniques, the benefit of fabric formwork is its properties of low-cost and easy transport. The process of fabric formwork is akin to molding and casting but having a soft boundary. Deformation of the fabric container is governed by force equilibrium between the pressure forces from liquid fill and tension in the stretched fabric. The final result of fabrication depends on the shapes of the flat panels, the fabrication orientation and the placement of external supports. Our computational framework generates optimized flat panels and fabrication orientation with reference to a target shape, and determines effective locations for external supports. We demonstrate the function of this design tool on a variety of models with different shapes and topology. Physical fabrication is also demonstrated to validate our approach.
<BR>
<p></p></tr>
</table>
<BR><BR>



<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/SIG19CurviSlice.jpg" width="160" border="0">
</td>
<td width=830 valign=top>
Jimmy Etienne,  Nicolas Ray, Daniele Panozzo, Samuel Hornus, <B>Charlie C.L. Wang</B>, 
Jonas Martinez, Sara McMains, Marc Alexa, Brian Wyvill, and Sylvain Lefebvre, 
"<a href="https://doi.org/10.1145/3306346.3323022" target="new">CurviSlicer: Slightly curved slicing for 3-axis printers</a>", ACM Transactions on Graphics (SIGGRAPH 2019), vol.38, no.4, article no.81 (11 pages), July 2019. 
<a href="pubs/SIG19CurviSlice.pdf" target="new">[PDF]</a>
<BR><BR>
<B>Abstract</B><BR>
Most additive manufacturing processes fabricate objects by stacking planar layers of solidified material. As a result, produced parts
exhibit a so-called staircase effect, which results from sampling slanted surfaces with parallel planes. Using thinner slices reduces this effect,  but it always remains visible where layers <I>almost</I> align with the input surfaces. In this research we exploit the ability of some additive manufacturing processes to deposit material slightly out of plane to dramatically reduce these artifacts. We focus in particular on the widespread Fused Filament Fabrication (FFF) technology, since most printers in this category can deposit along slightly curved paths, under deposition slope and thickness constraints. Our algorithm curves the layers, making them either follow the natural slope of the input surface or on the contrary, make them intersect the surfaces at a steeper angle thereby improving the sampling quality.
Rather than directly computing curved layers, our algorithm optimizes for a deformation of the model which is then sliced with a standard planar approach. We demonstrate that this approach enables us to encode all fabrication constraints, including the guarantee of generating collision-free toolpaths, in a convex optimization that can be solved using a QP solver. We produce a variety of models and compare print quality between curved deposition and planar slicing.
<BR>
<p></p></tr>
</table>
<BR><BR>



<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/ICRA19FermatCPP.png" width="160" border="0">
</td>
<td width=830 valign=top>
Chenming Wu, Chengkai Dai, Xiaoxi Gong, Yong-Jin Liu, Jun Wang, Xianfeng Gu, and <B>Charlie C.L. Wang</B>, "<a href="https://doi.org/10.1109/LRA.2019.2899920" target="new">Energy-efficient coverage path planning for general terrain surfaces</a>",
IEEE Robotics and Automation Letters, 
Presented at IEEE International Conference on Robotics and Automation (ICRA 2019), Montreal, Canada, May 20-24, 2019, vol.4, no.3, pp.2584-2591, July 2019. 
<a href="pubs/ICRA19FermatCPP.pdf" target="new">[PDF]</a> 
<a href="https://youtu.be/DEGBuFkZFpo" target="new">[Video@YouTube]</a> 
<BR><BR>
<B>Abstract</B><BR>
This paper tackles the problem of energy-efficient coverage path planning for exploring general surfaces by an autonomous vehicle. An efficient algorithms are developed to generate paths on freeform 3D surfaces according to a special design pattern as height-extremity-aware Fermat spiral for this purpose. By using the exact boundary-sourced geodesic distances, the method for generating Fermat spiral paths is first introduced to cover a general surface. Then, heuristics for energy-efficiency are incorporated to add peak points of a height-field as sources for geodesic computation. The paths generated by our method can significantly reduce the cost caused by gravity. Physical experiments have been taken on different terrain surfaces to demonstrate the effectiveness of our approach.
<BR>
<p></p></tr>
</table>
<BR><BR>


<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/CGANearPntLightPS.png" width="160" border="0"></td>
<td width=830 valign=top>
Wuyuan Xie, Ying Nie, Zhan Song, and <B>Charlie C.L. Wang</B>, 
"<a href="https://doi.org/10.1109/MCG.2019.2909360" target="new">Mesh-based computation for solving photometric stereo with near point lighting</a>", 
IEEE Computer Graphics and Applications, vol.39, no.3, pp.73-85, May/June 2019. 
<a href="pubs/CGANearPntLightPS.pdf" target="new">[PDF]</a> <a href="pubs/CGANearPntLightPS_CODE.zip" target="new">[Source Code & Data Set]</a>
<BR><BR>
(This is an extended version of the paper - <a href="https://doi.org/10.1109/CVPR.2015.7299089" target="new">Photometric stereo with near point lighting: A solution by mesh deformation</a>, 
which is published in 2015 IEEE CVPR Conference, Boston, Massachusetts, June 7-12, 2015.
<a href="pubs/CVPRNearPntLightingPS_DataSet.rar" target="new">[Data-Set]</a> 
<a href="http://youtu.be/Aspm4Rsr53A" target="new">[Video@YouTube]</a> 
)  
<BR><BR>
<B>Abstract</B>
<BR>
We tackle the problem of dense reconstruction with a practical system, in which near point lighting is employed. Different from the conventional formulation of photometric stereo that assumes parallel lighting, photometric stereo under the <I>near point lighting</I> (NPL) condition is a nonlinear problem as the local surface normals are coupled with its distance to the camera as well as the light sources. After obtaining the locations of point lights by a calibration process, we develop a new framework to solve this nonlinear reconstruction problem via mesh deformation, in which each facet is corresponding to a pixel in the image captured by the camera. In our framework, mesh deformation is decoupled into an iteration of interlaced steps of local projection and global blending. Experimental results verify that our method can generate accurate estimation of surface shape under NPL in a few iterations. Besides, this approach is robust to errors on the positions of light sources and is easy to be implemented.

<BR>
<p></p></tr>
</table>
<BR><BR>


<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/RoboSoft2019OutOfPlaneDeform.jpg" width="160" border="0">
</td>
<td width=830 valign=top>
Rob B.N. Scharff, Jun Wu, Jo Geraedts, and <B>Charlie C.L. Wang</B>, "Reducing out-of-plane deformation of soft robotic actuators for stable grasping", 
IEEE International Conference on Soft Robotics (RoboSoft 2019), Seoul, Korea, April 14-18, 2019. 
<a href="pubs/RoboSoft2019OutOfPlaneDeform.pdf" target="new">[PDF]</a> 
<a href="https://youtu.be/s6QkFtP809w" target="new">[Video@YouTube]</a> 
<BR><BR>
<B>Abstract</B><BR>
For grasping (unknown) objects, soft pneumatic actuators are primarily designed to bend towards a specific direction. Due to the flexibility of material and structure, soft actuators are also prone to out-of-plane deformations including twisting and sidewards bending, especially if the loading is asymmetric. In this paper, we demonstrate the negative effects of out-of-plane deformation on grasping. A structural design is proposed to reduce this type of deformation and thus improve grasping stability. Comparisons are first performed on soft pneumatic actuators with the same bending stiffness but different resistances to out-of-plane deformation, which is realized by changing the cross-section of the inextensible layer. To reduce out-of-plane deformation, a stiffening structure inspired by spatial flexures is integrated into the soft actuator. The integrated design is 3D printed using a single material. Physical experiments have been conducted to verify the improved grasping stability.
<BR>
<p></p></tr>
</table>
<BR><BR>


<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/TVCGBasRelief.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Mingqiang Wei, Yang Tian, Wai-Man Pang, <B>Charlie C.L. Wang</B>, Ming-Yong Pang, Jun Wang, Jing Qin, and Pheng-Ann Heng, 
"<a href="https://doi.org/10.1109/TVCG.2018.2818146" target="new">Bas-relief modeling from normal layers</a>", 
IEEE Transactions on Visualization and Computer Graphics, vol.25, no.4, pp.1651-1665, April 2019. 
<a href="pubs/TVCGBasRelief.pdf" target="new">[PDF]</a>
<BR><BR>
<B>Abstract</B><BR>
Bas-relief is characterized by its unique presentation of intrinsic shape properties and/or detailed appearance using materials raised up in different degrees above a background. 
However, many bas-relief modeling methods could not manipulate a scene's details well. We propose a simple and effective solution for two kinds of bas-relief modeling (i.e., structure-preserving and detail-preserving) which is different from the majority of tone mapping alike methods. Our idea originates from an observation on typical 3D models which are decomposed into a piecewise smooth <I>base layer</I> and a <I>detail layer</I> in normal field. Proper manipulation of the two layers contributes to both structure-preserving and detail-preserving bas-relief modeling. We solve the modeling problem in a discrete geometry processing setup that uses normal-based mesh processing as a theoretical foundation. In specific, using a two-step mesh smoothing mechanism as a bridge, we transfer the bas-relief modeling problem into a discrete space, and solve it in a least-squares manner. Experiments and comparisons to the state-of-the-art methods show that (i) geometry details are better preserved in a high compression, and (ii) structures are clearly preserved without shape distortion and interference from details.
<BR>
<p></p></tr>
</table>
<BR><BR>

<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/AMCompatibleStruc.jpg" width="160" border="0">
</td>
<td width=830 valign=top>
Eric Garner, Helena M.A. Kolken, <B>Charlie C.L. Wang</B>, Amir A. Zadpoor, and Jun Wu, "<a href="https://doi.org/10.1016/j.addma.2018.12.007" target="new">Compatibility in microstructural optimization for additive manufacturing</a>", Additive Manufacturing, vol.26, pp.65-75, March 2019. 
<a href="pubs/AMCompatibleStruc.pdf" target="new">[PDF]</a> 
<a href="http://homepage.tudelft.nl/z0s1z/projects/2018-compatibility-microstructures.html" target="new">[Project with Code]</a>
<BR><BR>
<B>Abstract</B><BR>
Microstructures with spatially-varying properties such as trabecular bone are widely seen in nature. These functionally graded materials possess smoothly changing microstructural topologies that enable excellent micro and macroscale performance. The fabrication of such microstructural materials is now enabled by additive manufacturing (AM). A challenging aspect in the computational design of such materials is ensuring compatibility between adjacent microstructures. Existing works address this problem by ensuring geometric connectivity between adjacent microstructural unit cells. In this paper, we aim to find the optimal connectivity between topology optimized microstructures. Recognizing the fact that the optimality of connectivity can be evaluated by the resulting physical properties of the assemblies, we propose to consider the assembly of adjacent cells together with the optimization of individual cells. In particular, our method simultaneously optimizes the physical properties of the individual cells as well as those of neighbouring pairs, to ensure material connectivity and smoothly varying physical properties. We demonstrate the application of our method in the design of functionally graded materials for implant design (including an implant prototype made by AM), and in the multiscale optimization of structures.
<BR>
<p></p></tr>
</table>
<BR><BR>

<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/TOGLineUp.jpg" width="160" border="0">
</td>
<td width=830 valign=top>
Minjing Yu, Zipeng Ye, Yongjin Liu, Ying He, and <B>Charlie C.L. Wang</B>, 
"<a href="https://doi.org/10.1145/3269979" target="new">LineUp: Computing chain-based physical transformation</a>", 
ACM Transactions on Graphics, vol.38, no.1, article no.11 (16 pages), February 2019. 
<a href="https://youtu.be/837B6xP7D5U" target="new">[Video@YouTube]</a>
<BR><BR>
<B>Abstract</B><BR>
In this paper, we introduce a novel method that can generate a sequence of physical transformations between 3D models with different shape and topology. Feasible transformations are realized on a chain structure with connected components that are 3D printed. Collision-free motions are computed to transform between different configurations of the 3D printed chain structure. To realize the transformation between different 3D models, we first voxelize these input models into similar number of voxels. The challenging part of our approach is to generate a simple path - as a chain configuration to connect most voxels. A layer-based algorithm is developed with theoretical guarantee of the existence and the path length. We find that collision-free motion sequence can always be generated when using a straight line as the intermediate configuration of transformation. The effectiveness of our method is demonstrated by both the simulation and the experimental tests taken on 3D printed chains.
<BR>
<p></p></tr>
</table>
<BR><BR>

<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/CADAdaptiveSlicing.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Huachao Mao, Tsz-Ho Kwok, Yong Chen, and <B>Charlie C.L. Wang</B>, 
"<a href="https://doi.org/10.1016/j.cad.2018.09.006" target="new">Adaptive slicing based on efficient profile analysis for additive manufacturing</a>", 
Computer-Aided Design, vol.107, pp.89-101, February 2019. 
<a href="pubs/CADAdaptiveSlicing.pdf" target="new">[PDF]</a> 
<BR><BR>
<B>Abstract</B><BR>
Adaptive slicing is an important computational task required in the layer-based manufacturing process. Its purpose is to find an optimal trade-off between the fabrication time (number of layers) and the surface quality (geometric deviation error). Most of the traditional adaptive slicing algorithms are computationally expensive or only based on local evaluation of errors. To tackle these problems, we introduce a method to efficiently generate the slicing plans by a new metric profile that can characterize the distribution of deviation errors along the building direction. By generalizing the conventional error metrics, the proposed metric profile is a density function of deviation errors, which measures the global deviation errors rather than the in-plane local geometry errors used in most prior methods. 
Slicing can be efficiently evaluated based on metric profiles in contrast to the expensive computation on  models in boundary-representation. An efficient algorithm based on dynamic programming is proposed to find the best slicing plan. Our adaptive slicing method can also be applied to models with weighted features and can serve as the inner loop to search the best building direction. The performance of our approach is demonstrated by experimental tests on different examples.
<BR>
<p></p></tr>
</table>
<BR><BR>





<a name="2018"></a>

<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/TVCGSupportFreeHollowing.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Weiming Wang, Yong-Jin Liu, Jun Wu, Shengjing Tian, <B>Charlie C.L. Wang</B>, Ligang Liu, and Xiuping Liu, "<a href="https://doi.org/10.1109/TVCG.2017.2764462" target="new">Support-free hollowing</a>", IEEE Transactions on Visualization and Computer Graphics, vol.24, no.10, pp.2787-2798, October 2018. 
<a href="pubs/TVCGSupportFreeHollowing.pdf" target="new">[PDF]</a> 
<a href="https://youtu.be/1lXH39TRrKM" target="new">[Video@YouTube]</a> 
<a href="pubs/TVCGSupportFreeHollowing_DataSet.zip" target="new">[Data Set]</a>
<BR><BR>
<B>Abstract</B><BR>
Offsetting-based hollowing is a solid modeling operation widely used in 3D printing, which can change the model's physical properties and reduce the weight by generating voids inside a model. However, a hollowing operation can lead to additional supporting structures for fabrication in interior voids, which cannot be removed. As a consequence, the result of a hollowing operation is affected by these additional supporting structures when applying the operation to optimize physical properties of different models. This paper proposes a support-free hollowing framework to overcome the difficulty of fabricating voids inside a solid. The challenge of computing a support-free hollowing is decomposed into a sequence of shape optimization steps, which are repeatedly applied to interior mesh surfaces. The optimization of physical properties in different applications can be easily integrated into our framework. Comparing to prior approaches that can generate support-free inner structures, our hollowing operation can reduce more volume of material and thus provide a larger solution space for physical optimization. Experimental tests are taken on a number of 3D models to demonstrate the effectiveness of this framework.
<BR>
<p></p></tr>
</table>
<BR><BR>


<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/SIG18RobotVolPrint.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Chengkai Dai, <B>Charlie C.L. Wang</B>, Chenming Wu, Sylvain Lefebvre, Guoxin Fang, and Yongjin Liu, 
"<a href="https://doi.org/10.1145/3197517.3201342" target="new">Support-free volume printing by multi-axis motion</a>", 
ACM Transactions on Graphics (SIGGRAPH 2018), vol.37, no.4, article no.134 (13 pages), July 2018. 
<a href="pubs/SIG18RobotVolPrint.pdf" target="new">[PDF]</a> 
<a href="pubs/SIG18RobotVolPrint_Supplementary.pdf" target="new">[Supplementary]</a> 
<a href="https://youtu.be/iaZeTlios0w" target="new">[Video@YouTube]</a> 
<a href="https://github.com/daichengkai/VoxelMultiAxisAM" target="new">[Source Code]</a>
<a href="Projects/gcodeMultiAxis3DP.html" target="new">[Toolpaths]</a>
<BR><BR>
<B>Abstract</B><BR>
This paper presents a new method to fabricate 3D models on a robotic printing system equipped with multi-axis motion. Materials are accumulated inside the volume along curved tool-paths so that the need of supporting structures can be tremendously reduced - if not completely abandoned - on all models. 
Our strategy to tackle the challenge of tool-path planning for multi-axis 3D printing is to perform two successive decompositions, first volume-to-surfaces and then surfaces-to-curves. The volume-to-surfaces decomposition is achieved by optimizing for a scalar field within the volume that represents the fabrication sequence. The field is constrained such that its iso-values represent curved layers that are supported from below, and present a convex surface affording for collision-free navigation of the printer head. After extracting all curved layers, the surfaces-to-curves decomposition covers them with tool-paths while taking into account constraints from the robotic deposition system. Our method successfully generates tool-paths for 3D printing models with large overhangs and high-genus topology. We fabricated several challenging cases on our robotic platform to verify and demonstrate its capabilities.
<BR>
<p></p></tr>
</table>
<BR><BR>

<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/CGAInteractiveChopper.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Aamir Khan Jadoon, Chenming Wu, Yong-Jin Liu, Ying He, and <B>Charlie C.L. Wang</B>, 
"<a href="https://doi.org/10.1109/MCG.2018.042731658" target="new">Interactive partitioning of 3D models into printable parts</a>", 
IEEE Computer Graphics and Applications, vol.38, no.4, pp.38-53, July/August 2018. [PDF] 
<a href="pubs/CGAInteractiveChopper_DataSet.zip" target="new">[Data Set]</a>

<BR><BR>
<B>Abstract</B>
<BR>
In this paper, we present an easy, flexible and interactive tool for partitioning a 3D model, which is larger 
than 3D-printer's working volume, into printable parts in an intuitive way. Our presented tool is based on 
the elegant partitioning optimization framework Chopper. Our tool aims at improving Chopper by 
providing users three easy-to-use interactive operations: no-go region painting, cutting plane specification 
and components re-union. With these operations, we show that (1) exhaustive search in the BSP tree - the 
most time-consuming step in Chopper - can be avoided, (2) more flexible geometric configurations can 
be provided, (3) user's design intention is considered naturally and efficiently, and customized 3D 
partitioning results can be obtained. We test our tool on a wide range of 3D models and observe promising 
results. A preliminary user study also demonstrates its effectiveness and efficiency.
<p></p></tr>
</table>
<BR><BR>


<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/TASEDeltaDLP3DPrinting.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Ran Yi, Chenming Wu, Yong-Jin Liu, Ying He, and <B>Charlie C.L. Wang</B>, 
"<a href="https://doi.org/10.1109/TASE.2017.2751664" target="new">Delta DLP 3D printing of large models</a>", IEEE Transactions on Automation Science and Engineering, vol.15, no.3, pp.1193-1204, July 2018. 
<a href="pubs/TASEDeltaDLP3DPrinting.pdf" target="new">[PDF]</a> 

<a href="https://youtu.be/jc6SRFnB05g" target="new">[Video@YouTube]</a>  

<BR><BR>
(This is an extended version of the paper - Delta DLP 3D printing with large size, 
which is published in 2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2016), Daejeon, Korea, October 9-14, 2016. <a href="pubs/IROS16Delta3DPrinter.pdf" target="new">[PDF]</a> 
<a href="https://youtu.be/UPPPm_i6lgc" target="new">[Video@YouTube]</a>)  
<BR><BR>
<B>Abstract</B><BR>
This paper presents a 3D printing system that uses a low-cost off-the-shelf consumer projector to fabricate large 
models. Compared with traditional DLP 3D printers using a single vertical carriage, the platform of our DLP 3D printer 
using delta mechanism can also move horizontally in the plane. We show that this system can print 3D models much larger than 
traditional DLP 3D printers. The major challenge to realize 3D printing of large models in our system comes from how to cover 
a planar polygonal domain by a minimum number of rectangles with fixed size, which is NP-hard. We propose a simple yet 
efficient approximation algorithm to solve this problem. The key idea is to segment a polygonal domain by using its medial axis 
and afterwards merge small parts in the segmentation. Given an arbitrary polygon Q with n generators (i.e., line segments and 
reflex vertices in Q), we show that the time complexity of our algorithm is O(n<sup>2</sup>log<sub>2</sub>n) and the number of output rectangles 
covering Q is O(Kn), where K is an input-polygon-dependent constant. A physical prototype system is built and several large 
3D models with complex geometric structures have been printed as examples to demonstrate the effectiveness.
<BR>
<p></p></tr>
</table>
<BR><BR>


<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/GMSelfSupportTruss.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Xiuping Liu, Liping Lin, Jun Wu, Weiming Wang, Baocai Yin, and <B>Charlie C.L. Wang</B>, 
"<a href="https://doi.org/10.1016/j.gmod.2018.05.001" target="new">Generating sparse self-supporting wireframe models for 3D printing using mesh simplification</a>", Graphical Models, selected papers from Computational Visual Media conference (CVM) 2018, vol.98, pp.14-23, July 2018. 
<BR><BR>
<B>Abstract</B><BR>
Wireframe models are becoming a popular option in 3D printing. 
Generating sparse wireframe models using classic mesh simplification methods leads to models that require a lot of support structures in the layer-upon-layer additive process. 
In this paper we present a mesh simplification method that takes into account the overhang angle. 
Specifically, we propose a metric for self-supportability. 
By combining this novel metric together with the classic error metrics for mesh simplification, our method generates sparse wireframe models that need much less supports. 
Moreover, the operations of vertex position and edge flipping are optimized to further increase self-supportability of the wireframe models. 
We demonstrate the effectiveness of the proposed method on a number of 3D models.
<BR>
<p></p></tr>
</table>
<BR><BR>


<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/ICRA18GeoSoftSimulator.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Guoxin Fang, Christopher-Denny Matte, Tsz-Ho Kwok, and <B>Charlie C.L. Wang</B>, 
"<a href="https://doi.org/10.1109/ICRA.2018.8461088" target="new">Geometry-based direct simulation for multi-material soft robots</a>", 
IEEE International Conference on Robotics and Automation (ICRA 2018), Brisbane, Australia, May 21-25, 2018. 
[PDF] 
<a href="https://youtu.be/vTKMGV1uf_c" target="new">[Video@YouTube]</a> 
<BR><BR>
<B>Abstract</B><BR>
Robots fabricated by soft materials can provide higher flexibility and thus better safety while interacting with natural objects with low stiffness such as food and human beings. However, as many more degrees of freedom are introduced, the motion simulation of a soft robot becomes cumbersome, especially when large deformations are presented. Moreover, when the actuation is defined by geometry variation, it is not easy to obtain the exact loads and material properties to be used in the conventional methods of deformation simulation. 
In this paper, we present a direct approach to take the geometric actuation as input and compute the deformed shape of soft robots by numerical optimization using a geometry-based algorithm. 
By a simple calibration, the properties of multiple materials can be modeled geometrically in the framework. 
Numerical and experimental tests have been conducted to demonstrate the performance of our approach on both cable-driven and pneumatic actuators in soft robotics.
<BR>
<p></p></tr>
</table>
<BR><BR>

<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/ICRA18BendingColorSensor.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Rob B.N. Scharff, Rens M. Doornbusch, Xander L. Klootwijk, Ajinkya A. Doshi, Eugeni L. Doubrovski, Jun Wu, Jo M.P. Geraedts, and <B>Charlie C.L. Wang</B>, 
"Color-based sensing of bending deformation on soft robots", 
IEEE International Conference on Robotics and Automation (ICRA 2018), Brisbane, Australia, May 21-25, 2018. 

<a href="pubs/ICRA18BendingColorSensor.pdf" target="new">[PDF]</a> 

<a href="https://youtu.be/j1VivpSscyU" target="new">[Video@YouTube]</a> 
<BR><BR>
<B>Abstract</B><BR>
This paper introduces a novel approach for sensing the bending deformation on soft robots by leveraging multicolor 3D printing. 
The measurement of deformation enables to complete the feedback loop of deformation control on soft actuators. The principle underlying our approach is that deformation is reflected by a change in color patterns, which can be detected by compact color sensors. 
Two novel designs are presented to generate color signals on 3D printed objects, which we call a structured generator and an integrated generator. 
Signal processing and calibration methods are developed to transform the color signal into a meaningful deformation metric. 
Our experimental tests taken on soft pneumatic actuators confirm that color signals can be stably generated and captured according to the bending deformation. The results demonstrate the usability of this sensing approach in deformation control. 
<BR>
<p></p></tr>
</table>
<BR><BR>

<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/WeightLBSDef.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Chuhua Xian, Shuo Jin, and <B>Charlie C.L. Wang</B>, 
"<a href="https://doi.org/10.1109/MCG.2017.2801409" target="new">Efficient C2-weighting for image warping</a>", IEEE Computer Graphics and Applications, vol.38, no.1, pp.59-76, January 2018. 
<a href="pubs/WeightLBSDef.pdf" target="new">[PDF]</a> 
<a href="pubs/WeightLBSDefMoreRes.pdf" target="new">[More Results]</a> 
<a href="https://youtu.be/nLyX36uIcuE" target="new">[Video@YouTube]</a>
<BR><BR>
<B>Abstract</B>
<BR>
Handle-driven image warping based on linear blending is widely used in many applications because of its merits on intuitiveness, efficiency and easiness of implementation. In this paper, we develop a method to compute high-quality weights within a closed domain for image warping. The property of C^2-continuity 
in weights is guaranteed by the carefully formulated basis functions. The efficiency of our algorithm is ensured by a closed-form formulation of the computation for weights. The cost of inserting a new handle is only the time to evaluate the distances from the new handle to all other sample points in the domain. A virtual handle insertion algorithm is developed to allow users to freely place handles within the domain while preserving the satisfaction of all expected criteria on weights for linear blending. Experimental examples for real-time applications are shown to demonstrate the effectiveness of this method.
<p></p></tr>
</table>
<BR><BR>






<a name="2017"></a>

<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/ROBIOEasySRRobot.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Minjing Yu, Yong-Jin Liu, and <B>Charlie C.L. Wang</B>, "<a href="https://doi.org/10.1109/ROBIO.2017.8324563" target="new">EasySRRobot: An easy-to-build self-reconfigurable robot with optimized design</a>", IEEE Conference on Robotics and Biomimetics, Macau, December 5-8, 2017. 

<a href="pubs/ROBIOEasySRRobot.pdf" target="new">[PDF]</a> 

<a href="https://youtu.be/oM3AB4tibKU" target="new">[Video@YouTube]</a> <b>(Finalist of Best Student Paper Award)</b> 
<BR><BR>
<B>Abstract</B><BR>
<I>Self-reconfigurable modular robots</I> (SRRobot) that can change their shape and function in different environments according to different tasks have caught a lot of attention recently. Most existing prototypes use professional electronic components with relatively expensive cost and high barrier of fabrication. In this paper, we present a low-cost SSRobot with double-cube modules. Our system is easy-to-build even for novices as all electric components are off-the-shelf and the structural components in plastics are made by 3D printing. To have a better design of interior structures, we first construct a design space for all feasible solutions that satisfy the constraints of fabrication. Then, an optimized solution is found by an objective function incorporating the factors of space utilization, structural soundness and assembly complexity. Thirty EasySRRobot modules are manufactured and assembled. The functionality of our algorithm is demonstrated by comparing an optimized interior design with other two feasible designs and realizing different motions on an EasySRRobot with four modules. 
<BR>
<p></p></tr>
</table>
<BR><BR>


<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/UIST2017ThermalComfortCast.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Xiaoting Zhang, Guoxin Fang, Chengkai Dai, Jouke Verlinden, Jun Wu, Emily Whiting, and <B>Charlie C.L. Wang</B>, 
"<a href="https://doi.org/10.1145/3126594.3126600" target="new">Thermal-comfort design of personalized casts</a>", ACM Symposium on User Interface Software and Technology (UIST), pp.243-254, Quebec City, Canada, October 22-25, 2017. 

<a href="pubs/UIST2017ThermalComfortCast.pdf" target="new">[PDF]</a> 

<a href="https://youtu.be/K2tkBQnQGzA" target="new">[Video@YouTube]</a> 
<BR><BR>
<B>Abstract</B><BR>
This paper introduces a novel method for designing personalized orthopedic casts which are aware of thermal-comfort while satisfying mechanical requirements. Our pipeline starts from thermal images taken by an infrared camera, by which the distribution of thermal-comfort sensitivity is generated on the surface of a 3D scanned model. We formulate a hollowed Voronoi tessellation pattern to represent the covered region for a web-like cast design. The pattern is further optimized according to the thermal-comfort sensitivity calculated from thermal images. Working together with a thickness variation method, we generate a solid model for a personalized cast maximizing both thermal comfort and mechanical stiffness. To demonstrate the effectiveness of our approach, 3D printed models of personalized casts are tested on body parts of different individuals.
<BR>
<p></p></tr>
</table>
<BR><BR>


<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/CADReuseIGA.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Gang Xu, Tsz-Ho Kwok, and <B>Charlie C.L. Wang</B>, 
"<a href="https://doi.org/10.1016/j.cad.2017.04.002" target="new">Isogeometric computation reuse method for complex objects with topology-consistent volumetric parameterization</a>", 
Computer-Aided Design, vol.91, pp.1-13, October 2017. <a href="pubs/CADReuseIGA.pdf" target="new">[PDF]</a> 
<BR><BR>
<B>Abstract</B><BR>
Volumetric spline parameterization and computational efficiency are two major challenges in <I>isogeometric analysis</I> (IGA). 
To tackle this problem, we propose a framework of computation reuse in 
IGA on a set of three-dimensional models with similar semantic features. Given a template domain, 
B-spline based consistent volumetric parameterization is first constructed for a set of models with 
similar semantic features. An effcient quadrature-free method is investigated in our framework 
to compute the entries of stiffness matrix by B&eacutezier extraction and polynomial approximation. 
In our approach, evaluation on the stiffness matrix and imposition of the boundary conditions can be 
pre-computed and reused during IGA on a set of CAD models. Examples with complex geometry 
are presented to show the effectiveness of our methods, and efficiency similar to the computation 
in linear finite element analysis can be achieved for IGA taken on a set of models.
<BR>
<p></p></tr>
</table>
<BR><BR>






<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/RoboMotionImitation.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Shuo Jin, Chengkai Dai, Yang Liu, and <B>Charlie C.L. Wang</B>, 
"<a href="https://doi.org/10.1115/1.4036923" target="new">Motion imitation based on sparsely sampled correspondence</a>", 
ASME Transactions - Journal of Computing and Information Science in Engineering, vol.17, no.4, 041009 (7 pages), June, 2017. 

<a href="pubs/JCISEMotionImitation.pdf" target="new">[PDF]</a> <a href="https://youtu.be/ok3uFYFEU0I" target="new">[Video@YouTube]</a>
<BR><BR>
<B>Abstract</B>
<BR>
Existing techniques for motion imitation often suffer a certain level of latency due to their computational overhead or a large set of correspondence samples to search. To achieve real-time imitation with small latency, we present a framework in this paper to reconstruct motion on humanoids based on sparsely sampled correspondence. The imitation problem is formulated as finding the projection of a point from the configuration space of a human's poses into the configuration space of a humanoid.  
<p></p></tr>
</table>
<BR><BR>  



<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/ICRA17RoboFDM.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Chenming Wu, Chengkai Dai, Guoxin Fang, Yong-Jin Liu, and <B>Charlie C.L. Wang</B>, 
"<a href="https://doi.org/10.1109/ICRA.2017.7989140" target="new">RoboFDM: a robotic system for support-free fabrication using FDM</a>", 
IEEE International Conference on Robotics and Automation (ICRA 2017), Singapore, May 29 - June 3, 2017, pp.1175-1180. 
<a href="pubs/ICRA17RoboFDM.pdf" target="new">[PDF]</a> 
<a href="https://youtu.be/mrR7lKpHo9k" target="new">[Video@YouTube]</a>
<BR><BR>
<B>Abstract</B><BR>
This paper presents a robotic system - RoboFDM that targets at printing 3D models without support-structures, which is considered as the major restriction to the flexibility of 3D printing. The hardware of RoboFDM consists of a robotic arm providing 6-DOF motion to the platform of material accumulation and an extruder forming molten filaments of <I>polylactic acid</I> (PLA). The fabrication of 3D models in this system follows the principle of <I>fused decomposition modeling</I> (FDM). Different from conventional FDM, an input model fabricated by RoboFDM is printed along different directions at different places. A new algorithm is developed to decompose models into support-free parts that can be printed one by one in a collision-free sequence. The printing directions of all parts are also determined during the computation of  model decomposition. Experiments have been successfully taken on our RoboFDM system to print general freeform objects in a support-free manner.
<BR>
<p></p></tr>
</table>
<BR><BR>


<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/CSRS_GPU.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Lianping Xing, <B>Charlie C.L. Wang</B>, and Kin-Chuen Hui, 
"<a href="http://dx.doi.org/10.1016/j.cad.2017.01.002" target="new">Coherent spherical range-search for dynamic points on GPUs</a>", 
Computer-Aided Design, vol.86, pp.12-25, May 2017.
<a href="pubs/CADDistQuery.pdf" target="new">[PDF]</a> 
<a href="Projects/CSRSProj.htm" target="new">[Project Page - with Code]</a> 
<a href="https://github.com/DebbieLeung/CSRS" target="new">[DLL Library]</a> 
<a href="http://youtu.be/LTMe5je9beE" target="new">[Video@YouTube for Particle Simulation]</a>
<BR><BR>
<B>Abstract</B>
<BR>
We present an approach to accelerate <I>spherical range-search</I> (SRS) for dynamic points that employs the
computational power of many-core GPUs. Unlike finding k <I>approximate nearest neighbours</I> (ANNs), exact SRS is
needed in geometry processing and physical simulation to avoid missing small features. The spatial coherence of query
points and the temporal coherence of dynamic points are exploited in our approach to achieve very efficient
range-search on AABB-trees. We test our coherent SRS in several applications including point-point-set geometry processing, distance-field generation and particle-based simulation, which are best scenarios to present the spatial and the temporal coherence of spherical queries on dynamic points. On a PC with NVIDIA GTX 660 Ti GPUs, our approach can take 1M queries on 1M dynamic points at a rate of 1600 queries/ms, where 49 neighbours are found on average within the range of 1/100 of the bounding-box's diagonal length. We observe an increase of up to 4x compared with conventional voxel-based GPU searching approaches in the benchmark of particle-based fluid simulation. Moreover, the speedup can be scaled up to 150x when being applied to highly non-uniform distribution of particles in the simulation. 
<p></p></tr>
</table>
<BR><BR>  

<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/RPJAMFGeometry.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Kai-Ming Yu, Yu Wang, and <B>Charlie C.L. Wang</B>, 
"<a href="http://dx.doi.org/10.1108/RPJ-06-2015-0067" target="new">Smooth geometry generation in additive manufacturing file format: problem study and new formulation</a>", 
Rapid Prototyping Journal, vol.23, no.1, 2017. <a href="pubs/RPJAMFGeometry.pdf" target="new">[PDF]</a> 
<BR><BR>
<B>Abstract</B>
<BR>
In the newly released ASTM standard specification for Additive Manufacturing File (AMF) format - version 1.1, Hermite curve based interpolation is employed to refine input triangles to generate denser mesh with smoother geometry. This paper studies the problems of constructing smooth geometry based on Hermite interpolation on curves and proposes a solution to overcome these problems. A formulation using triangular Bezier patch is proposed in this paper to generate smooth geometry from input polygonal models. Different configurations on the boundary curves are analysed to further enrich this formulation. 
The proposed scheme has requirements for the input normals of a model, only C^0 interpolation can be generated on those cases with less-proper input. 
For these cases, the Boolean sum and the Nielson's point-opposite edge interpolation for triangular Coons patch are used to generate the smooth geometry as a C^0 interpolant.
<p></p></tr>
</table>
<BR><BR>



<a name="2016"></a>

<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/AMTOptimalFitting.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Yunbo Zhang, <B>Charlie C.L. Wang</B>, and Karthik Ramani, 
"<a href="http://dx.doi.org/10.1007/s00170-016-8669-2" target="new">Optimal fitting of strain-controlled flattenable mesh surfaces</a>", 
International Journal of Advanced Manufacturing Technology, vol.87, no.9, pp.2873-2887, December 2016. <a href="pubs/AMTOptimalFitting.pdf" target="new">[PDF]</a> 
<BR><BR>
<B>Abstract</B>
<BR>
A flattenable mesh surface is a polygonal mesh surface that can be unfolded into a planar patch without stretching
any polygon. This paper presents a new method for computing a slightly stretched flattenable mesh surface M from
a piecewise-linear surface patch P in 3D, where the shape approximation error between M and P is minimised
and the strain of stretching on M is controlled. Prior approaches result in either a flattenable surface that could be
quite different from the input shape or a (discrete) developable surface has relative simple shape. The techniques
investigated in this paper overcome these difficulties. First, we introduce a new surface modeling method to conduct
a sequence of nearly isometric deformations to morph a flattenable mesh surface to a new shape which has a better
approximation of the input surface. Second, in order to get better initial surfaces for fitting and overcome topological
obstacles, a shape perturbation scheme is investigated to obtain the optimal surface fitting result. Last, to improve the
scalability of our optimal surface fitting algorithm, a coarse-to-fine fitting framework is exploited so that very dense
flattenable mesh surfaces can be modeled and boundaries of the input surfaces can be interpolated.
<p></p></tr>
</table>
<BR><BR>




<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/CADInfillOptm.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Jun Wu, <B>Charlie C.L. Wang</B>, Xiaoting Zhang, and R&uumldiger Westermann, 
"<a href="http://dx.doi.org/10.1016/j.cad.2016.07.006" target="new">Self-supporting rhombic infill structures for additive manufacturing</a>", 
Computer-Aided Design, vol.80, pp.32-42, November 2016. 
<a href="pubs/CADInfillOptm.pdf" target="new">[PDF]</a> 
<a href="pubs/CADInfillOptm_DataSet.zip" target="new">[Data Set]</a>
<BR><BR>
<B>Abstract</B>
<BR>
Recent work has demonstrated that the interior material layout of a 3D model can be designed to make a fabricated replica satisfy application-specific demands on its physical properties, such as resistance to external loads. A widely used practice to fabricate such models is by layer-based additive manufacturing (AM), which however suffers from the problem of adding and removing interior supporting structures. In this paper, we present a novel method for generating application-specific infill structures on rhombic cells so that the resultant structures can automatically satisfy manufacturing requirements on overhang-angle and wall-thickness. Additional supporting structures can be avoided entirely in our framework. To achieve this, we introduce the usage of an adaptive rhombic grid, which is built from an input surface model. Starting from the initial sparse set of rhombic cells, via numerical optimization techniques an objective function can be improved by adaptively subdividing the rhombic grid and thus adding more walls in cells. We demonstrate the effectiveness of our method for generating interior designs in the applications of improving mechanical stiffness and static stability.
<p></p></tr>
</table>
<BR><BR>



<!----------------<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/IROS16Delta3DPrinter.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Chenming Wu, Ran Yi, Yong-Jin Liu, Ying He, and <B>Charlie C.L. Wang</B>, 
"Delta DLP 3D printing with large size", 
2016 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS 2016), Daejeon, Korea, October 9-14, 2016. 
<a href="pubs/IROS16Delta3DPrinter.pdf" target="new">[PDF]</a>  
<a href="https://youtu.be/UPPPm_i6lgc" target="new">[Video@YouTube]</a>
<BR><BR>
<B>Abstract</B>
<BR>
We present a delta DLP 3D printer with large size in this paper. Compared with traditional DLP 3D printers that use a low-cost off-the-shelf consumer projector and a single vertical carriage, the platform of our delta DLP 3D printer can also move horizontally in the plane. We show that this structure allows the printer to have a larger printing area than the projection area of a projector. 
Our system can print 3D models much larger than traditional DLP 3D printers. The major challenge to realize delta 3D printing with large size comes from how to partition an arbitrary planar polygonal shape (possibly with holes or multiple disjoint polygons) into a minimum number of rectangles with fixed size, which is NP-hard. We propose a simple yet efficient approximation algorithm to solve this problem. The time complexity of our algorithm is <i>O</i>(<i>n</i>&sup3 log <i>n</i>), where <i>n</i> is the number of edges in the polygonal shape. A physical prototype system is built and several large 3D models with complex geometric structures have been printed as examples to demonstrate the effectiveness of our approach.
<p></p></tr>
</table>
<BR><BR>
------------->

<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/SGPBendingDesign.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Xiaoting Zhang, Xinyi Le, Zhihao Wu, Emily Whiting, and <B>Charlie C.L. Wang</B>, 
"<a href="http://dx.doi.org/10.1111/cgf.12972" target="new">Data-driven bending elasticity design by shell thickness</a>", 
Computer Graphics Forum, Eurographics Symposium on Geometry Processing 2016, June 20-24, 2016, Berlin, Germany, vol.35, no.5, pp.157-166, 2016. 
<a href="pubs/SGPBendingDesign.pdf" target="new">[PDF]</a> 
<a href="pubs/SGPBendingDesignTRAppendix.pdf" target="new">[Extended Technical Report]</a> 
<a href="https://youtu.be/QC55I5bOCkY" target="new">[Video@YouTube]</a>
<BR><BR>
<B>Abstract</B>
<BR>
We present a method to design the deformation behavior of 3D printed models by an interactive tool,
where the variation of bending elasticity at different regions of a model is realized by a change in shell thickness.
Given a soft material to be used in 3D printing, we propose an experimental setup to acquire the bending behavior
of this material on tubes with different diameters and thicknesses.
The relationship between shell thickness and bending elasticity is stored in an echo state network using the acquired dataset. With the help of the network,
an interactive design tool is developed to generate non-uniformly hollowed models to achieve desired bending behaviors.
The effectiveness of this method is verified on models fabricated by different 3D printers by studying whether their physical deformation can match the designed target shape.
<p></p></tr>
</table>
<BR><BR>


<table width=“1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/HRBFClosedFormRecon.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Shengjun Liu, <B>Charlie C.L. Wang</B>, Guido Brunnett, and Jun Wang, 
"<a href="http://dx.doi.org/10.1016/j.cad.2016.05.001" target="new">A closed-form formulation of HRBF-based surface reconstruction by approximate solution</a>", Computer-Aided Design, 
Special Issue of 2016 Symposium on Solid and Physical Modeling, June 20-24, 2016, Berlin, Germany, vol.78, pp.147-157, September 2016. 
<a href="pubs/SPMHRBFSurfRecon.pdf" target="new">[PDF]</a> 
<a href="https://github.com/gcvgroup/hrbfqi" target="new">[Source Code]</a> 
<a href="https://github.com/GCVGroup/HRBFQI/tree/master/Bin/Data" target="new">[Data Set]</a>
<BR><BR>
<B>Abstract</B>
<BR>
The <I>Hermite radial basis functions</I> (HRBFs) implicits have been used to reconstruct surfaces from scattered Hermite data points. In this work, we propose a closed-form formulation to construct HRBF-based implicits by a quasi-solution to approximate the exact one. A scheme is developed to automatically adjust the support sizes of basis functions to hold the error bound of a quasi-solution. Our method can generate an implicit function from positions and normals of scattered points without taking any global operation. Robust and efficient reconstructions are observed in our experimental tests on real data captured from a variety of scenes.
<BR><BR>
(Supplementary Technical Report - "Error-bound, comparison and sub-sampling for closed-form HRBF surface reconstruction" 
<a href="pubs/HRBFSurfReconTR.pdf" target="new">[PDF]</a>)
<p></p></tr>
</table>
<BR><BR>


<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/ICRA16RopeCaging.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Tsz Ho Kwok, Weiwei Wan, Jia Pan, <B>Charlie C.L. Wang</B>, Jianjun Yuan, Kensuke Harada, and Yong Chen, 
"<a href="http://dx.doi.org/10.1109/ICRA.2016.7487345" target="new">Rope caging and grasping</a>", 
IEEE International Conference on Robotics and Automation (ICRA 2016), pp.1980-1986, Stockholm, Sweden, May 16-21, 2016.  
<a href="pubs/ICRA16RopeCaging.pdf" target="new">[PDF]</a> 
<a href="https://youtu.be/a3zooXy9dvU" target="new">[Video@YouTube]</a>
<BR><BR>
<B>Abstract</B>
<BR>
We present a novel method for caging grasps in this paper by stretching ropes on the surface of a 3D object. 
Both topology and shape of a model to be grasped has been considered in our approach. Our algorithm can guarantee generating local minimal rings on every topological branches of a given model with the help of 
a Reeb graph. Cages and grasps can then be computed from these rings, and 
physical experimental tests have been conducted to verify the robustness of our approach.
<p></p></tr>
</table>
<BR><BR>

<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/ICRA16SwarmSteering.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Qianwen Chao, Jiangfan Yu, Chengkai Dai, Tiantian Xu, Li Zhang, <B>Charlie C.L. Wang</B>, and Xiaogang Jin, 
"<a href="http://dx.doi.org/10.1109/ICRA.2016.7487731" target="new">Steering micro-robotic swarm by dynamic actuating fields</a>", 
IEEE International Conference on Robotics and Automation (ICRA 2016), pp.5230-5235, Stockholm, Sweden, May 16-21, 2016.
<a href="pubs/ICRA16SwarmSteering.pdf" target="new">[PDF]</a> 
<a href="https://youtu.be/RP2ZIOFttQs" target="new">[Video@YouTube]</a>
<BR><BR>
<B>Abstract</B>
<BR>
We present a general solution for steering micro-robotic swarm by dynamic actuating fields. In our approach, the motion
of micro-robots is controlled by changing the actuating direction of a field applied to them. The time-series sequence
of actuating field's directions can be computed automatically. Given a target position in the domain of swarm, a
governing field is first constructed to provide optimal moving directions at every points. Following these directions,
a robot can be driven to the target efficiently. However, when working with a crowd of micro-robots, the optimal moving
directions on different agents can contradict with each other. To overcome this difficulty, we develop a novel steering
algorithm to compute a statistically optimal actuating direction at each time frame. Following a sequence of these
actuating directions, a crowd of micro-robots can be transported to the target region effectively. Our steering
strategy of swarm has been verified on a platform that generates magnetic fields with unique actuating directions.
Experimental tests taken on aggregated magnetic micro-particles are quite encouraging.
<p></p></tr>
</table>
<BR><BR>

<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/TVCGStyling.jpg" width="162" border="0"></td>
<td width=830 valign=top>
Tsz-Ho Kwok, Yanqiu Zhang, <B>Charlie C.L. Wang</B>, Yong-Jin Liu, and Kai Tang, 
"<a href="http://dx.doi.org/10.1109/TVCG.2015.2446472" target="new">Styling evolution for tight-fitting garments</a>", 
IEEE Transactions on Visualization and Computer Graphics, vol.22, no.5, pp.1580-1591, May 2016. 
<a href="pubs/TVCGStyling.pdf" target="new">[PDF]</a> 
<a href="http://youtu.be/2kPebpvS0Y8" target="new">[Video@YouTube]</a> 
<a href="http://sites.google.com/site/kwoktszho2009/research/design-evolution" target="new">[Project Page - with Data-Set]</a>
<BR><BR>
<B>Abstract</B>
<BR>
We present an evolution method for designing the styling curves of garments. 
The procedure of evolution is driven by aesthetics-inspired scores to evaluate the quality of styling designs, where the aesthetic considerations are represented in the form of streamlines on human bodies.  
A dual representation is introduced in our platform to process the styling curves of designs, based on which robust methods for realizing the operations of evolution are developed. 
Starting from a given set of styling designs on human bodies, we demonstrate the effectiveness of set evolution inspired by aesthetic factors. The evolution is adaptive to the change of aesthetic inspirations. 
By this adaptation, our platform can automatically generate new designs fulfilling the demands of variations in different human bodies and poses.
<p></p></tr>
</table>
<BR><BR>


<B>Book Chapter and Survey Papers</B>

<BR><BR>
<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/BookChapterContinuousFiber3DP.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Chi-Chung Li, Chengkai Dai, Wei-Hsin Liao, and <B>Charlie C.L. Wang</B>, "Towards direct deposition of continuous-fibers on curved surfaces", Recent Advances in Additive Manufacturing, 2019, accepted. 
[PDF] 
<BR><BR>
<B>Abstract</B>
<BR>
The purpose of this article is to explore the possible methodology to realize the direct deposition of continuous fibers in a sandwich structure on curved 3D surfaces. Preliminary tests have been conducted to demonstrate the performance improvement. Physical experiments are conducted on a hardware setup with 6 degrees-of-freedom (DOF) motion provided by a robotic arm. With the help of such a hardware platform, we are able to reinforce 3D printed parts by a process of continuous-fiber deposition between layers of PLA matrix in 3D printing.
<p></p></tr>
</table>
<BR><BR>




<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/JCISEStatusAMTech.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Yuen-Shan Leung, Tsz-Ho Kwok, Xiangjia Li, Yang Yang, <B>Charlie C.L. Wang</B>, and Yong Chen, "Challenges and status on design and computation for emerging additive manufacturing technologies", ASME Transactions - Journal of Computing and Information Science in Engineering, vol.19, no.2, 021013 (21 pages), March 2019. <a href="pubs/JCISEEmergingAM.pdf" target="new">[PDF]</a> 
<BR><BR>
<B>Abstract</B>
<BR>
The revolution of additive manufacturing (AM) has led to many opportunities in fabricating complex and novel products. The increase of the printable materials and the emergence of the various fabricating processes continuously expand the capability of manufacturing. Our products are no longer limited to be single material, single scale or single function. In fact, a paradigm shift is taking place in the industries from geometry-centered usage to support functional demands, and hence it is expected to resolve wide range of complex and difficult problems. Although AM provides us higher design degree of freedom beyond the geometry to fabricate new objects with tailored properties and functions, there are only very few approaches for computational design in this new domain enabled by AM. The objectives of this study are to provide an overview on the current computer-aided design methodologies that are applied to multi-material, multi-scale, multi-form and multi-functional AM technologies. We summarize the difficulties encountered in the design approaches and emphasize the need for the future development. The study also introduces the related manufacturing processes, lists their present applications, and discusses their potential future trends.
<p></p></tr>
</table>
<BR><BR>




<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/SMOTopoOptmAMSurvey.jpg" width="160" border="0"></td>
<td width=830 valign=top>
Jikai Liu, Andrew T. Gaynor, Shikui Chen, Zhan Kang, Krishnan Suresh, Akihiro Takezawa, Lei Li, Junji Kato, Jinyuan Tang, <B>Charlie C.L. Wang</B>, Lin Cheng, Xuan Liang, and Albert C To, "<a href="http://dx.doi.org/10.1007/s00158-018-1994-3" target="new">Current and future trends in topology optimization for additive manufacturing</a>", Structural and Multidisciplinary Optimization, vol.57, no.6, pp.2457-2483, June 2018.
<BR><BR>
<B>Abstract</B>
<BR>
Manufacturing-oriented topology optimization has been extensively studied the past two decades, in particular for the conventional manufacturing methods, e.g., machining and injection molding or casting. Both design and manufacturing engineers have benefited from these efforts because of the close-to-optimal and friendly-to-manufacture design solutions. Recently, additive manufacturing (AM) has received significant attention from both academia and industry. The motivation of this perspective paper is to summarize the state-of-art topology optimization methods for a variety of AM topics. At the same time, this paper also expresses the authors' perspectives on the challenges and opportunities in these topics.
<p></p></tr>
</table>
<BR><BR>



<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/SoftRoboticsChapter2016.png" width="160" border="0"></td>
<td width=830 valign=top>
Rob B.N. Scharff, Eugeni L. Doubrovski, Wim A. Poelman, Pieter P. Jonker, <B>Charlie C.L. Wang</B>, and Jo M.P. Geraedts, 
"<a href="http://link.springer.com/chapter/10.1007/978-3-319-46460-2_4" target="new">Towards behavior design of a 3D-printed soft robotic hand</a>", 
Soft Robotics: Trends, Applications and Challenges, Proceedings of the Soft Robotics Week, 
pp.23-29, April 25-30, 2016, Livorno, Italy, Springer. <a href="https://youtu.be/AdMhkIM4hwA" target="new">[Video@YouTube]</a>
<BR><BR>
<B>Abstract</B>
<BR>
This work presents an approach to integrate actuators, sensors, and structural components into a single product that is 3D printed using Selective Laser Sintering. 
The behavior of actuators, sensors, and structural components is customized to desired functions within the product. Our approach is demonstrated 
by the realization of human-like behavior in a 3D-printed soft robotic hand. This work describes the first steps towards creating the desired behavior by means of
modeling specific volumes within the product using Additive Manufacturing. Our work shows that it is not necessary to limit the design of a soft robotic product to
only integrating off-the-shelf components but instead we deeply embedded the design of the required behavior in the process of designing the actuators, sensors and structural components.
<p></p></tr>
</table>
<BR><BR>



<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/MicroFabCh5.jpg" width="160" border="0"></td><td width=830 valign=top>
Tsz-Ho Kwok, Yong Chen, and <B>Charlie C.L. Wang</B>, 
"<a href="http://dx.doi.org/10.1016/B978-0-323-35321-2.00007-8" target="new">Geometric analysis and computation using Layered Depth-Normal Images for three-dimensional microfabrication</a>", 
Chapter 5, Three-Dimensional Microfabrication Using Two-photon Polymerization, pp.119-147, 2016. 
<BR><BR>
<B>Abstract</B>
<BR>
<I>Additive manufacturing</I> (AM) is a direct manufacturing process that provides the ability to fabricate parts with complex shape. Robust geometric computation is essential to deal with the complex geometry. Current geometric computation methods based on the <I>boundary representation</I> (B-rep) explicitly define and compute geometry. However, such approaches lack in simplicity and are prone to robustness problems. In this chapter, a point-based geometric computation method based on the <I>Layered Depth-Normal Image</I> (LDNI) is presented. A set of computation algorithms are developed for this new point-based method, including the conversions between the LDNI and B-rep models, the offsetting and the Boolean geometric operations, etc. A number of test cases has shown the robustness of the developed geometric operations, and a set of <I>Computer-Aided Design and Manufacturing</I> (CAD/CAM) applications related to the complex component design and manufacturing has also been explored.
<p></p></tr>
</table>
<BR><BR>


<a name="UnderReview"></a>

<B>Under Review</B>
<BR><BR>






<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/CAD3DHumanByCNN.jpg" width="160" border="0"></td><td width=830 valign=top>
Bin Liu, Xiuping Liu, Zhixin Yang, and <B>Charlie C.L. Wang</B>, "<a href="https://arxiv.org/abs/1912.11616" target="new">Concise and effective network for 3D human modeling from orthogonal silhouettes</a>", under review. 
<a href="https://youtu.be/JEPAmiB0wYI" target="new">[Video@YouTube]</a> 
<BR><BR>
<B>Abstract</B>
<BR>
In this paper, we revisit the problem of 3D human modeling from two orthogonal silhouettes of individuals (i.e., front and side views). Different from our prior work, a supervised learning approach based on \textit{convolutional neural network} (CNN) is investigated to solve the problem by establishing a mapping function that can effectively extract features from two silhouettes and fuse them into coefficients in the shape space of human bodies. A new CNN structure is proposed in our work to exact not only the discriminative features of front and side views and also their mixed features for the mapping function. 3D human models with high accuracy are synthesized from coefficients generated by the mapping function. Existing CNN approaches for 3D human modeling usually learn a large number of parameters (from 8M to 350M) from two binary images. Differently, we investigate a new network architecture and conduct the samples on silhouettes as input. As a consequence, more accurate models can be generated by our network with only 2.5M coefficients. The training of our network is conducted on samples obtained by augmenting a publicly accessible dataset. Learning transfer by using datasets with a smaller number of scanned models is applied to our network to enable the function of generating results with gender-oriented (or geographical) patterns.
<p></p></tr>
</table>
<BR><BR>







<table width="1000" border="0" cellpadding="0" cellspacing="0" tableborder="0"><tr>
<td align="center" valing="top" noresize><td valign=top align=left width=170>
<img src="pubs/CADLatticeImplicitModeling.jpg" width="160" border="0"></td><td width=830 valign=top>
Shengjun Liu, Tao Liu, Weiming Wang, Eugeni L. Doubrovski, and <B>Charlie C.L. Wang</B>, "Memory-efficient modeling of adaptive lattice structures for additive manufacturing", under review. 
<BR><BR>
<B>Abstract</B>
<BR>
Lattice structures have been widely used in different applications of additive manufacturing due to its many superior physical properties. When being directly modeled by triangular meshes, a lattice structure with high complexity in geometry consumes a lot of memory. This prevents the usage of lattice structures in large scale applications (e.g., to design the interior structure of a solid with spatially graded material properties). In this paper, we propose a memory-efficient method to model adaptive lattice structures. Only a graph together with the radii of its edges are stored for representing a lattice structure. The corresponding solid for a lattice structure is generated locally by convolution surface in a streaming manner when slicing the solid. As a result, only limited memory is consumed for generating the planar contours for fabrication. Lattice structures with a massive number of struts can be effectively and efficiently modeled and processed. Different from distance-field, solid models represented by convolution surfaces have naturally blended shape at the intersections of struts which can avoid the stress concentration at regions with curvature discontinuity. Algorithms have also been developed in our framework to minimize the need of supporting structures and to generate a lattice structure meeting the designed density distribution.
<p></p></tr>
</table>
<BR><BR>


</td><tr><td colspan=3 align=center><P><BR><P><BR></td></tr></table>
<BR><BR> 

</font></BODY></HTML>